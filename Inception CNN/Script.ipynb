{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from getvector import getvector\n",
    "from tensorflow.python.platform import gfile\n",
    "from progress.bar import Bar\n",
    "\n",
    "\n",
    "\n",
    "if len(sys.argv) <= 1:\n",
    "    print ('enter option: \"train\" or \"test <image file name>\"')\n",
    "    exit()\n",
    "\n",
    "\n",
    "data_inputs = []\n",
    "data_labels = []\n",
    "\n",
    "# Checking if the 2048-dimensional vector representations of the training images are already available\n",
    "if os.path.isfile('./data_inputs.txt') and os.path.isfile('./data_labels.txt'):\n",
    "    data_inputs = np.loadtxt('data_inputs.txt')\n",
    "    data_labels = np.loadtxt('data_labels.txt')\n",
    "\n",
    "else: \n",
    "    # add in your images here if you want to train the model on your own images\n",
    "    image_dir = './train'\n",
    "    file_list = []\n",
    "    file_glob = os.path.join(image_dir, '*.jpg')\n",
    "    file_list.extend(gfile.Glob(file_glob))\n",
    "\n",
    "    # I only used 300 images from the cats and dogs dataset\n",
    "    file_list = file_list[0:300]\n",
    "    bar = Bar('Inception-V3 is processing images:', max=300)\n",
    "    for file_name in file_list:\n",
    "        data_inputs.append(getvector(file_name))\n",
    "        if 'cat' in file_name:\n",
    "            data_labels.append([1, 0])\n",
    "        else:\n",
    "            data_labels.append([0, 1])\n",
    "        bar.next()\n",
    "    bar.finish()\n",
    "\n",
    "    np.savetxt('data_inputs.txt', data_inputs)\n",
    "    np.savetxt('data_labels.txt', data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type either train or test!\n"
     ]
    }
   ],
   "source": [
    "train_inputs, valtest_inputs, train_labels, valtest_labels = train_test_split(data_inputs, data_labels, test_size=0.3, random_state=42)\n",
    "val_inputs, test_inputs, val_labels, test_labels = train_test_split(valtest_inputs, valtest_labels, test_size=0.4, random_state=43)\n",
    "\n",
    "# Setting hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "log_batch_step = 50\n",
    "\n",
    "# useful info\n",
    "n_features = np.size(train_inputs, 1)\n",
    "n_labels = np.size(train_labels, 1)\n",
    "\n",
    "# Placeholders for input features and labels\n",
    "inputs = tf.placeholder(tf.float32, (None, n_features))\n",
    "labels = tf.placeholder(tf.float32, (None, n_labels))\n",
    "\n",
    "# Setting up weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal((n_features, n_labels), stddev=0.1), name='weights')\n",
    "bias = tf.Variable(tf.zeros(n_labels), name='bias')\n",
    "tf.add_to_collection('vars', weights)\n",
    "tf.add_to_collection('vars', bias)\n",
    "\n",
    "# Setting up operation in fully connected layer\n",
    "logits = tf.add(tf.matmul(inputs, weights), bias)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "tf.add_to_collection('pred', prediction)\n",
    "\n",
    "# Defining loss of network\n",
    "difference = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "loss = tf.reduce_sum(difference)\n",
    "\n",
    "# Defining optimiser\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Define accuracy\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))\n",
    "\n",
    "saver = tf.train.Saver((weights, bias))\n",
    "\n",
    "if sys.argv[1] == 'train':\n",
    "# Run tensorflow session\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        # Running the training in batches \n",
    "        batch_count = int(math.ceil(len(train_inputs)/batch_size))\n",
    "\n",
    "        for epoch_i in range(epochs):\n",
    "            batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "            # The training cycle\n",
    "            for batch_i in batches_pbar:\n",
    "                # Get a batch of training features and labels\n",
    "                batch_start = batch_i*batch_size\n",
    "                batch_inputs = train_inputs[batch_start:batch_start + batch_size]\n",
    "                batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "                # Run optimizer\n",
    "                _ = sess.run(optimizer, feed_dict={inputs: batch_inputs, labels: batch_labels})\n",
    "            \n",
    "\n",
    "            # Check accuracy against validation data\n",
    "            val_accuracy, val_loss = sess.run([accuracy, loss], feed_dict={inputs: val_inputs, labels: val_labels})\n",
    "            print(\"After epoch {}, Loss: {}, Accuracy: {}\".format(epoch_i+1, val_loss, val_accuracy))\n",
    "\n",
    "        g = tf.get_default_graph()\n",
    "        saver.save(sess, 'testsave')\n",
    "\n",
    "\n",
    "elif sys.argv[1] == 'test':\n",
    "    try: \n",
    "        file_name = sys.argv[2]\n",
    "    except IndexError:\n",
    "        print ('please enter image file path.........')\n",
    "        exit()\n",
    "    image_input = getvector(file_name).reshape((1,2048))\n",
    "    if 'cat' in file_name:\n",
    "        image_label = [[1, 0]]\n",
    "    else:\n",
    "        image_label = [[0, 1]]\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        new_saver = tf.train.import_meta_graph('testsave.meta')\n",
    "        new_saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "\n",
    "        prediction = sess.run(prediction, feed_dict={inputs: image_input})\n",
    "        print ('It\\'s a cat: {}, It\\'s a dog: {}'.format(prediction[0][0], prediction[0][1]))\n",
    "\n",
    "else:\n",
    "    print ('type either train or test!')\n",
    "    exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
