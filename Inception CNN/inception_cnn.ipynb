{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from getvector import getvector\n",
    "from tensorflow.python.platform import gfile\n",
    "from progress.bar import Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if len(sys.argv) <= 1:\n",
    "    print ('enter option: \"train\" or \"test <image file name>\"')\n",
    "    exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_inputs = []\n",
    "data_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_inputs = np.loadtxt('data_inputs.txt')\n",
    "data_labels = np.loadtxt('data_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_dir = './Trin'\n",
    "file_list = []\n",
    "file_glob = os.path.join(image_dir, '*.jpg')\n",
    "file_list.extend(gfile.Glob(file_glob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I only used 300 images from the cats and dogs dataset\n",
    "file_list = file_list[0:300]\n",
    "bar = Bar('Inception-V3 is processing images:', max=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for file_name in file_list:\n",
    "    data_inputs.append(getvector(file_name))\n",
    "    if 'cat' in file_name:\n",
    "        data_labels.append([1, 0])\n",
    "    else:\n",
    "        data_labels.append([0, 1])\n",
    "    bar.next()\n",
    "bar.finish()\n",
    "\n",
    "np.savetxt('data_inputs.txt', data_inputs)\n",
    "np.savetxt('data_labels.txt', data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_inputs, valtest_inputs, train_labels, valtest_labels = train_test_split(data_inputs, data_labels, test_size=0.3, random_state=42)\n",
    "val_inputs, test_inputs, val_labels, test_labels = train_test_split(valtest_inputs, valtest_labels, test_size=0.4, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_train = len(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "hm_epochs = 3\n",
    "log_batch_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_features = np.size(train_inputs, 1)\n",
    "n_labels = np.size(train_labels, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, n_features))\n",
    "y = tf.placeholder(tf.float32, (None, n_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.truncated_normal((n_features, n_labels), stddev=0.1), name='weights')\n",
    "bias = tf.Variable(tf.zeros(n_labels), name='bias')\n",
    "tf.add_to_collection('vars', weights)\n",
    "tf.add_to_collection('vars', bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits = tf.add(tf.matmul(x, weights), bias)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "tf.add_to_collection('pred', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "difference = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_sum(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-25-b94b5ed94d65>:2: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch 0 completed out of 3 loss 612.936811447\n",
      "Epoch 1 completed out of 3 loss 311.75328064\n",
      "Epoch 2 completed out of 3 loss 76.4353916645\n",
      "Accuracy: 0.888889\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        \n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            num_batch = int(n_train/batch_size)+1\n",
    "            for _ in range(num_batch):\n",
    "                randidx = np.random.randint(n_train, size=batch_size)\n",
    "                epoch_x,epoch_y = train_inputs[randidx, :],train_labels[randidx, :]\n",
    "                _,c = sess.run([optimizer,loss], feed_dict = {x:epoch_x,y:epoch_y})\n",
    "                epoch_loss+=c\n",
    "            print('Epoch', epoch, 'completed out of', hm_epochs,'loss',epoch_loss)\n",
    "                \n",
    "        correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        print('Accuracy:', accuracy.eval({x:test_inputs, y :test_labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
